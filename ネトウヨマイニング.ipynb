{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rBxCd5hSioW7",
    "outputId": "8fee43d9-693f-4a88-9f76-77fa49d1d0ad"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: ginza in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (5.1.2)\n",
      "Requirement already satisfied: ja-ginza in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (5.1.2)\n",
      "Requirement already satisfied: plac>=1.3.3 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from ginza) (1.3.5)\n",
      "Requirement already satisfied: SudachiDict-core>=20210802 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from ginza) (20221021)\n",
      "Requirement already satisfied: SudachiPy<0.7.0,>=0.6.2 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from ginza) (0.6.6)\n",
      "Requirement already satisfied: spacy<3.5.0,>=3.2.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from ginza) (3.4.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from spacy<3.5.0,>=3.2.0->ginza) (2.28.1)\n",
      "Requirement already satisfied: wasabi<1.1.0,>=0.9.1 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from spacy<3.5.0,>=3.2.0->ginza) (0.10.1)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from spacy<3.5.0,>=3.2.0->ginza) (1.10.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from spacy<3.5.0,>=3.2.0->ginza) (4.64.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from spacy<3.5.0,>=3.2.0->ginza) (3.1.2)\n",
      "Requirement already satisfied: pathy>=0.3.5 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from spacy<3.5.0,>=3.2.0->ginza) (0.6.2)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from spacy<3.5.0,>=3.2.0->ginza) (2.4.5)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from spacy<3.5.0,>=3.2.0->ginza) (2.0.7)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from spacy<3.5.0,>=3.2.0->ginza) (3.3.0)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from spacy<3.5.0,>=3.2.0->ginza) (1.0.3)\n",
      "Requirement already satisfied: typer<0.5.0,>=0.3.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from spacy<3.5.0,>=3.2.0->ginza) (0.4.2)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from spacy<3.5.0,>=3.2.0->ginza) (21.3)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from spacy<3.5.0,>=3.2.0->ginza) (3.0.8)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.10 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from spacy<3.5.0,>=3.2.0->ginza) (3.0.10)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from spacy<3.5.0,>=3.2.0->ginza) (1.0.9)\n",
      "Requirement already satisfied: thinc<8.2.0,>=8.1.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from spacy<3.5.0,>=3.2.0->ginza) (8.1.5)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from spacy<3.5.0,>=3.2.0->ginza) (2.0.8)\n",
      "Requirement already satisfied: setuptools in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from spacy<3.5.0,>=3.2.0->ginza) (65.3.0)\n",
      "Requirement already satisfied: numpy>=1.15.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from spacy<3.5.0,>=3.2.0->ginza) (1.23.4)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from packaging>=20.0->spacy<3.5.0,>=3.2.0->ginza) (3.0.9)\n",
      "Requirement already satisfied: smart-open<6.0.0,>=5.2.1 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from pathy>=0.3.5->spacy<3.5.0,>=3.2.0->ginza) (5.2.1)\n",
      "Requirement already satisfied: typing-extensions>=4.1.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<1.11.0,>=1.7.4->spacy<3.5.0,>=3.2.0->ginza) (4.4.0)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.2.0->ginza) (1.26.12)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.2.0->ginza) (2022.9.24)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.2.0->ginza) (3.4)\n",
      "Requirement already satisfied: charset-normalizer<3,>=2 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.5.0,>=3.2.0->ginza) (2.1.1)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.2.0->ginza) (0.0.3)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from thinc<8.2.0,>=8.1.0->spacy<3.5.0,>=3.2.0->ginza) (0.7.9)\n",
      "Requirement already satisfied: colorama in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.5.0,>=3.2.0->ginza) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from typer<0.5.0,>=0.3.0->spacy<3.5.0,>=3.2.0->ginza) (8.1.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from jinja2->spacy<3.5.0,>=3.2.0->ginza) (2.1.1)\n",
      "Requirement already satisfied: nlplot in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (1.6.0)\n",
      "Requirement already satisfied: networkx in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from nlplot) (2.8.8)\n",
      "Requirement already satisfied: pandas in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from nlplot) (1.5.1)\n",
      "Requirement already satisfied: plotly>=4.12.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from nlplot) (5.11.0)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from nlplot) (1.1.3)\n",
      "Requirement already satisfied: ipython in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from nlplot) (8.6.0)\n",
      "Requirement already satisfied: seaborn in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from nlplot) (0.12.1)\n",
      "Requirement already satisfied: pillow in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from nlplot) (9.3.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from nlplot) (4.64.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from nlplot) (3.6.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from nlplot) (1.23.4)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from nlplot) (1.8.2.2)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from plotly>=4.12.0->nlplot) (8.1.0)\n",
      "Requirement already satisfied: traitlets>=5 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from ipython->nlplot) (5.5.0)\n",
      "Requirement already satisfied: backcall in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from ipython->nlplot) (0.2.0)\n",
      "Requirement already satisfied: jedi>=0.16 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from ipython->nlplot) (0.18.1)\n",
      "Requirement already satisfied: decorator in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from ipython->nlplot) (5.1.1)\n",
      "Requirement already satisfied: pickleshare in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from ipython->nlplot) (0.7.5)\n",
      "Requirement already satisfied: pygments>=2.4.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from ipython->nlplot) (2.13.0)\n",
      "Requirement already satisfied: matplotlib-inline in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from ipython->nlplot) (0.1.6)\n",
      "Requirement already satisfied: prompt-toolkit<3.1.0,>3.0.1 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from ipython->nlplot) (3.0.32)\n",
      "Requirement already satisfied: stack-data in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from ipython->nlplot) (0.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from ipython->nlplot) (0.4.6)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from matplotlib->nlplot) (2.8.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from matplotlib->nlplot) (3.0.9)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from matplotlib->nlplot) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from matplotlib->nlplot) (4.38.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from matplotlib->nlplot) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from matplotlib->nlplot) (1.0.6)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from matplotlib->nlplot) (21.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from pandas->nlplot) (2022.6)\n",
      "Requirement already satisfied: scipy>=1.3.2 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from scikit-learn->nlplot) (1.9.3)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from scikit-learn->nlplot) (3.1.0)\n",
      "Requirement already satisfied: joblib>=1.0.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from scikit-learn->nlplot) (1.2.0)\n",
      "Requirement already satisfied: parso<0.9.0,>=0.8.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from jedi>=0.16->ipython->nlplot) (0.8.3)\n",
      "Requirement already satisfied: wcwidth in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from prompt-toolkit<3.1.0,>3.0.1->ipython->nlplot) (0.2.5)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->nlplot) (1.16.0)\n",
      "Requirement already satisfied: executing>=1.2.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from stack-data->ipython->nlplot) (1.2.0)\n",
      "Requirement already satisfied: asttokens>=2.1.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from stack-data->ipython->nlplot) (2.1.0)\n",
      "Requirement already satisfied: pure-eval in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from stack-data->ipython->nlplot) (0.2.2)\n",
      "Requirement already satisfied: wordcloud in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (1.8.2.2)\n",
      "Requirement already satisfied: numpy>=1.6.1 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from wordcloud) (1.23.4)\n",
      "Requirement already satisfied: pillow in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from wordcloud) (9.3.0)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from wordcloud) (3.6.2)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from matplotlib->wordcloud) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from matplotlib->wordcloud) (2.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from matplotlib->wordcloud) (1.0.6)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from matplotlib->wordcloud) (0.11.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from matplotlib->wordcloud) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from matplotlib->wordcloud) (21.3)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from matplotlib->wordcloud) (4.38.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kkk\\.virtualenvs\\twitter-avulh5z9\\lib\\site-packages (from python-dateutil>=2.7->matplotlib->wordcloud) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install -U ginza ja-ginza\n",
    "!pip install nlplot\n",
    "!pip install wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tGLaCjkwcwmF"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'WordCloud' from 'wordcloud' (C:\\twitter\\wordcloud.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [8], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnlplot\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\n",
      "File \u001b[1;32m~\\.virtualenvs\\twitter-AvUlH5z9\\lib\\site-packages\\nlplot\\__init__.py:1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnlplot\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mnlplot\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mmain\u001b[39m():\n\u001b[0;32m      5\u001b[0m     \u001b[38;5;28;01mpass\u001b[39;00m\n",
      "File \u001b[1;32m~\\.virtualenvs\\twitter-AvUlH5z9\\lib\\site-packages\\nlplot\\nlplot.py:19\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_objs\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mgo\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[1;32m---> 19\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mwordcloud\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m WordCloud\n\u001b[0;32m     20\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnx\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnetworkx\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01malgorithms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m community\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'WordCloud' from 'wordcloud' (C:\\twitter\\wordcloud.py)"
     ]
    }
   ],
   "source": [
    "import nlplot\n",
    "import pandas as pd\n",
    "import plotly\n",
    "from plotly.subplots import make_subplots\n",
    "from plotly.offline import iplot\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EpK6VzrSVzOi",
    "outputId": "dbf6ccbc-c87e-4344-aebd-00dc325865be"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:3326: DtypeWarning:\n",
      "\n",
      "Columns (21,22) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0                              @mototaka728 わしは勝ったのか負けたのか…\n",
       "1        ★緊急告知★\\r\\n\\r\\n本日、14時30分より、YouTubeライブ配信を行ないます。\\...\n",
       "2        ベンツのSクラスでは自慢にもならんよ。\\r\\nロールスかベントレーくらいじゃないと。\\r\\n...\n",
       "3                                               その車、知りたい！😅\n",
       "4        ちなみに、大学を中退して43年、同級生に会ったのは、3人だけ。うち2人は偶然。\\r\\nわしっ...\n",
       "                               ...                        \n",
       "52759    @yurinbow先日は有難うございました。百田です。わけのわからない話しかできずに申し訳あ...\n",
       "52760                    @SAWAYA_fezanいつもお世話になっております。百田です。\n",
       "52761    @yurindo_ebisu初めまして、百田と申します。検索していたらぶつかりました。影法師...\n",
       "52762           @yuka24初めまして。検索したらぶつかりました。ご購入予定ありがとうございます＾\n",
       "52763                         友人に勧められて、アホみたいにtwitteを始めた＾＾；\n",
       "Name: rawContent, Length: 52764, dtype: object"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(f'/content/drive/MyDrive/調査資料/百田尚樹/hyakutanaoki.csv',encoding=\"utf-8\")\n",
    "\n",
    "df[\"rawContent\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6FiU-2XbWI4y",
    "outputId": "c8c86275-1100-42b0-d737-78383fcc0591"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52764/52764 [24:55<00:00, 35.29it/s]\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from tqdm import tqdm\n",
    "\n",
    "nlp = spacy.load(\"ja_ginza\")\n",
    "\n",
    "words_list = []\n",
    "for story in tqdm(df[\"rawContent\"]):\n",
    "  doc = nlp(story)\n",
    "  words = []\n",
    "  for token in doc:\n",
    "    if token.tag_ in [\"名詞-普通名詞-一般\",\"動詞-一般\",\"形容詞-一般\"]:\n",
    "      words.append(token.lemma_)\n",
    "  words_list.append(\" \".join(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "E8z3ZsjlYvaM",
    "outputId": "fe7544c6-aef8-4738-95f9-2e0e8b1068ee"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning:\n",
      "\n",
      "Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "df[\"特徴語\"] = pd.NA\n",
    "vectorizer = TfidfVectorizer()\n",
    "X = vectorizer.fit_transform(words_list)\n",
    "words = vectorizer.get_feature_names()\n",
    "for book_id, vec in zip(range(len(words_list)), X.toarray()):\n",
    "  feature_words = []\n",
    "  for w_id, tfidf in sorted(enumerate(vec), key=lambda x: x[1], reverse=True):\n",
    "    if tfidf < 0.1:\n",
    "      break\n",
    "    feature_word = words[w_id]\n",
    "    feature_words.append(feature_word)  \n",
    "  df.at[book_id,\"特徴語\"] = feature_words\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mfi7AJodZ5Za"
   },
   "outputs": [],
   "source": [
    "import nlplot\n",
    "npt = nlplot.NLPlot(df, target_col=\"特徴語\")\n",
    "stopwords = npt.get_stopword(top_n=0,min_freq=3) + [\"こと\",\"いう\",\"もつ\",\"よる\",\"とも\",\"思う\",\"つく\",\"はず\",\"https\",\"co\",\"gt\",\"言う\",\"自分\",\"to\",\"new\",\"the\",\"jnsc\",\"posted\",\"of\",\"for\",\"and\",\"in\",\"you\",\"nikone\",\"san\",\"www\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4IzgINKfaFPb"
   },
   "outputs": [],
   "source": [
    "fig_unigram = npt.bar_ngram(\n",
    "    title='uni-gram',\n",
    "    xaxis_label='word_count',\n",
    "    yaxis_label='word',\n",
    "    ngram=1,\n",
    "    top_n=50,\n",
    "    width=800,\n",
    "    height=1100,\n",
    "    color=None,\n",
    "    horizon=True,\n",
    "    stopwords=stopwords,\n",
    "    verbose=False,\n",
    "    save=True,\n",
    ")\n",
    "fig_unigram.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFjr3Cv3afsR"
   },
   "outputs": [],
   "source": [
    "# 単語数の分布\n",
    "fig_histgram = npt.word_distribution(\n",
    "    title='word distribution',\n",
    "    xaxis_label='count',\n",
    "    yaxis_label='',\n",
    "    width=1000,\n",
    "    height=500,\n",
    "    color=None,\n",
    "    template='plotly',\n",
    "    bins=None,\n",
    "    save=True,\n",
    ")\n",
    "fig_histgram.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aqwGpHDiaq0O"
   },
   "outputs": [],
   "source": [
    "fig_wc = npt.wordcloud(\n",
    "    width=1000,\n",
    "    height=600,\n",
    "    max_words=100,\n",
    "    max_font_size=100,\n",
    "    colormap='tab20_r',\n",
    "    stopwords=stopwords,\n",
    "    mask_file=None,\n",
    "    save=True\n",
    ")\n",
    "plt.figure(figsize=(15, 25))\n",
    "plt.imshow(fig_wc, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vwGnzgtge0Vf"
   },
   "outputs": [],
   "source": [
    "# ビルド（データ件数によっては処理に時間を要します）\n",
    "npt.build_graph(stopwords=stopwords, min_edge_frequency=25)\n",
    "\n",
    "# ビルド後にノードとエッジの数が表示される。ノードの数が100前後になるようにするとネットワークが綺麗に描画できる\n",
    "\n",
    "\n",
    "fig_co_network = npt.co_network(\n",
    "    title='Co-occurrence network',\n",
    "    sizing=100,\n",
    "    node_size='adjacency_frequency',\n",
    "    color_palette='hls',\n",
    "    width=1100,\n",
    "    height=700,\n",
    "    save=True\n",
    ")\n",
    "iplot(fig_co_network)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Dip-nRnLhSNE"
   },
   "outputs": [],
   "source": [
    "fig_sunburst = npt.sunburst(\n",
    "    title='sunburst chart',\n",
    "    colorscale=True,\n",
    "    color_continuous_scale='Oryel',\n",
    "    width=1000,\n",
    "    height=800,\n",
    "    save=True\n",
    ")\n",
    "fig_sunburst.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AV_MRRiBuNfE"
   },
   "outputs": [],
   "source": [
    "fig_treemap = npt.treemap(\n",
    "    title='Tree map',\n",
    "    ngram=1,\n",
    "    top_n=50,\n",
    "    width=1300,\n",
    "    height=600,\n",
    "    stopwords=stopwords,\n",
    "    verbose=False,\n",
    "    save=True\n",
    ")\n",
    "fig_treemap.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yRRdrUg0utzs"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
